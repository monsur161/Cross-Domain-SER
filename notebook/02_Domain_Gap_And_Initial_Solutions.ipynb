{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Quantifying the Domain Gap and Exploring Initial Solutions\n",
    "\n",
    "**Objective:** After establishing a strong baseline, this phase is dedicated to rigorously defining the core research problem.\n",
    "\n",
    "Our workplan is as follows:\n",
    "1.  **Create a More Robust Specialist:** We will retrain our Specialist model using on-the-fly data augmentation and early stopping to create the best possible version.\n",
    "2.  **Conduct a Cross-Domain Evaluation:** We will take this robust model and test it on a different, more challenging dataset (CREMA-D) to precisely measure its failure to generalize.\n",
    "3.  **Test a First Solution:** We will explore Knowledge Distillation as an initial, simple method to see if it can solve the domain generalization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49001,
     "status": "ok",
     "timestamp": 1756704317501,
     "user": {
      "displayName": "Monsur Abdullah",
      "userId": "12726162145146472590"
     },
     "user_tz": -360
    },
    "id": "Sez7OE2AtHb4",
    "outputId": "86fe78b6-7bf5-4252-dbb1-b8286e837364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
      "Collecting resampy\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting praat-parselmouth\n",
      "  Downloading praat_parselmouth-0.4.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.42.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n",
      "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
      "  Downloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
      "  Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
      "  Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
      "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading praat_parselmouth-0.4.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading audiomentations-0.42.0-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.5/86.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18 kB)\n",
      "Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (109 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-stretch, praat-parselmouth, resampy, numpy-rms, numpy-minmax, audiomentations\n",
      "Successfully installed audiomentations-0.42.0 numpy-minmax-0.5.0 numpy-rms-0.6.0 praat-parselmouth-0.4.6 python-stretch-0.3.1 resampy-0.4.3\n"
     ]
    }
   ],
   "source": [
    "# --- Mount Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Install All Necessary Packages ---\n",
    "!pip install librosa resampy praat-parselmouth audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1223716,
     "status": "ok",
     "timestamp": 1756705588029,
     "user": {
      "displayName": "Monsur Abdullah",
      "userId": "12726162145146472590"
     },
     "user_tz": -360
    },
    "id": "PPBJ5GQvtMD1",
    "outputId": "c10bef98-4d6b-458d-d711-77c271b97939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting audio to spectrogram conversion for RAVDESS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing RAVDESS Actors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [20:22<00:00, 50.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAVDESS spectrogram conversion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- This script creates the pre-computed spectrograms for RAVDESS ---\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "AUDIO_PATH = \"/content/drive/MyDrive/ser_project/ravdess_data/\"\n",
    "SPECTROGRAM_PATH = \"/content/drive/MyDrive/ser_project/ravdess_spectrograms/\"\n",
    "os.makedirs(SPECTROGRAM_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Starting audio to spectrogram conversion for RAVDESS...\")\n",
    "actor_folders = [f for f in os.listdir(AUDIO_PATH) if os.path.isdir(os.path.join(AUDIO_PATH, f))]\n",
    "for actor_folder in tqdm(actor_folders, desc=\"Processing RAVDESS Actors\"):\n",
    "    actor_path = os.path.join(AUDIO_PATH, actor_folder)\n",
    "    for file_name in os.listdir(actor_path):\n",
    "        try:\n",
    "            file_path = os.path.join(actor_path, file_name)\n",
    "            audio, sr = librosa.load(file_path, res_type='kaiser_fast', duration=3, sr=22050*2, offset=0.5)\n",
    "            spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
    "            db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "            output_filename = os.path.join(SPECTROGRAM_PATH, f\"{os.path.splitext(file_name)[0]}.npy\")\n",
    "            np.save(output_filename, db_spectrogram)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {file_path}: {e}\")\n",
    "\n",
    "print(\"\\nRAVDESS spectrogram conversion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Creating a More Robust Specialist Model\n",
    "\n",
    "To ensure our test is as fair as possible, we first create a stronger Specialist model. We enhance the training process from Phase 1 in two key ways:\n",
    "* **On-the-Fly Augmentation:** We now apply random pitch shifts and add Gaussian noise directly to the raw audio during training. This prevents the model from simply memorizing the training data and forces it to learn more fundamental features of emotional speech.\n",
    "* **Early Stopping:** The model's state is saved only when it achieves a new best performance on the validation set, preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3982487,
     "status": "ok",
     "timestamp": 1756709994312,
     "user": {
      "displayName": "Monsur Abdullah",
      "userId": "12726162145146472590"
     },
     "user_tz": -360
    },
    "id": "0uiw0kJJtO63",
    "outputId": "874b47b9-6efb-40b7-b7e7-80e45ad45f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 147MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main training with augmentation and early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:58<00:00,  3.29s/it]\n",
      "Epoch 1/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 1.6597 | Val Loss: 1.6046 | Val Acc: 52.08%\n",
      "ğŸ‰ New best validation accuracy: 52.08%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.39s/it]\n",
      "Epoch 2/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | Train Loss: 1.2291 | Val Loss: 2.2854 | Val Acc: 37.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:59<00:00,  3.31s/it]\n",
      "Epoch 3/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | Train Loss: 0.9685 | Val Loss: 3.3568 | Val Acc: 34.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.38s/it]\n",
      "Epoch 4/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | Train Loss: 0.8515 | Val Loss: 1.8425 | Val Acc: 42.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:03<00:00,  3.42s/it]\n",
      "Epoch 5/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | Train Loss: 0.7350 | Val Loss: 1.8061 | Val Acc: 52.78%\n",
      "ğŸ‰ New best validation accuracy: 52.78%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:04<00:00,  3.46s/it]\n",
      "Epoch 6/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | Train Loss: 0.6054 | Val Loss: 1.4610 | Val Acc: 56.94%\n",
      "ğŸ‰ New best validation accuracy: 56.94%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.36s/it]\n",
      "Epoch 7/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | Train Loss: 0.6307 | Val Loss: 4.8132 | Val Acc: 26.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.35s/it]\n",
      "Epoch 8/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | Train Loss: 0.3575 | Val Loss: 0.7941 | Val Acc: 72.92%\n",
      "ğŸ‰ New best validation accuracy: 72.92%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:02<00:00,  3.40s/it]\n",
      "Epoch 9/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | Train Loss: 0.2264 | Val Loss: 0.7483 | Val Acc: 75.00%\n",
      "ğŸ‰ New best validation accuracy: 75.00%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:04<00:00,  3.46s/it]\n",
      "Epoch 10/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | Train Loss: 0.2257 | Val Loss: 0.7471 | Val Acc: 75.69%\n",
      "ğŸ‰ New best validation accuracy: 75.69%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.36s/it]\n",
      "Epoch 11/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | Train Loss: 0.1959 | Val Loss: 0.7935 | Val Acc: 75.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:02<00:00,  3.39s/it]\n",
      "Epoch 12/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | Train Loss: 0.1515 | Val Loss: 0.7745 | Val Acc: 73.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.35s/it]\n",
      "Epoch 13/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | Train Loss: 0.1477 | Val Loss: 0.7753 | Val Acc: 73.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:02<00:00,  3.41s/it]\n",
      "Epoch 14/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | Train Loss: 0.1374 | Val Loss: 0.7800 | Val Acc: 74.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:02<00:00,  3.39s/it]\n",
      "Epoch 15/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | Train Loss: 0.1252 | Val Loss: 0.7725 | Val Acc: 74.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:02<00:00,  3.39s/it]\n",
      "Epoch 16/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | Train Loss: 0.1105 | Val Loss: 0.7564 | Val Acc: 75.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:03<00:00,  3.42s/it]\n",
      "Epoch 17/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | Train Loss: 0.1151 | Val Loss: 0.7733 | Val Acc: 74.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.34s/it]\n",
      "Epoch 18/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | Train Loss: 0.1131 | Val Loss: 0.7818 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.38s/it]\n",
      "Epoch 19/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 | Train Loss: 0.1165 | Val Loss: 0.7920 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:58<00:00,  3.30s/it]\n",
      "Epoch 20/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 | Train Loss: 0.1083 | Val Loss: 0.7854 | Val Acc: 76.39%\n",
      "ğŸ‰ New best validation accuracy: 76.39%. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:59<00:00,  3.33s/it]\n",
      "Epoch 21/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 | Train Loss: 0.1018 | Val Loss: 0.7763 | Val Acc: 75.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.38s/it]\n",
      "Epoch 22/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 | Train Loss: 0.1201 | Val Loss: 0.7904 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:01<00:00,  3.38s/it]\n",
      "Epoch 23/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:08<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 | Train Loss: 0.0931 | Val Loss: 0.7856 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:59<00:00,  3.32s/it]\n",
      "Epoch 24/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 | Train Loss: 0.1056 | Val Loss: 0.7773 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.34s/it]\n",
      "Epoch 25/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 | Train Loss: 0.1054 | Val Loss: 0.7848 | Val Acc: 74.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:00<00:00,  3.36s/it]\n",
      "Epoch 26/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:10<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 | Train Loss: 0.1037 | Val Loss: 0.7892 | Val Acc: 75.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [01:59<00:00,  3.33s/it]\n",
      "Epoch 27/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 | Train Loss: 0.1078 | Val Loss: 0.8031 | Val Acc: 74.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:03<00:00,  3.43s/it]\n",
      "Epoch 28/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 | Train Loss: 0.1021 | Val Loss: 0.7752 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:04<00:00,  3.45s/it]\n",
      "Epoch 29/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 | Train Loss: 0.1042 | Val Loss: 0.7836 | Val Acc: 75.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:03<00:00,  3.44s/it]\n",
      "Epoch 30/30 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:11<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 | Train Loss: 0.1001 | Val Loss: 0.7893 | Val Acc: 74.31%\n",
      "\n",
      "--- FINAL EVALUATION ON RAVDESS TEST SET ---\n",
      "Loading best model from epoch with accuracy: 76.39%\n",
      "Final Model Accuracy on Test Set: 80.56%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.71      0.50      0.59        10\n",
      "        calm       0.83      0.79      0.81        19\n",
      "       happy       0.67      0.74      0.70        19\n",
      "         sad       0.78      0.74      0.76        19\n",
      "       angry       0.84      0.84      0.84        19\n",
      "     fearful       0.76      0.80      0.78        20\n",
      "     disgust       0.94      0.89      0.92        19\n",
      "    surprise       0.86      1.00      0.93        19\n",
      "\n",
      "    accuracy                           0.81       144\n",
      "   macro avg       0.80      0.79      0.79       144\n",
      "weighted avg       0.81      0.81      0.80       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- This script trains the main ResNet18 model with augmentation and early stopping ---\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, numpy as np, librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import models\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift\n",
    "\n",
    "# --- Configuration ---\n",
    "AUDIO_PATH = \"/content/drive/MyDrive/ser_project/ravdess_data/\"\n",
    "LEARNING_RATE = 0.001; BATCH_SIZE = 32; EPOCHS = 30\n",
    "CHECKPOINT_BEST_PATH = \"/content/drive/MyDrive/ser_project/resnet_best_augmented.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Mappings and Augmenter ---\n",
    "emotion_map = { \"01\": 0, \"02\": 1, \"03\": 2, \"04\": 3, \"05\": 4, \"06\": 5, \"07\": 6, \"08\": 7 }\n",
    "emotion_labels_list = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprise\"]\n",
    "augmenter = Compose([AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.4), PitchShift(min_semitones=-4, max_semitones=4, p=0.4)])\n",
    "\n",
    "# --- Dataset for On-the-Fly Augmentation ---\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_width=300, augment=False):\n",
    "        self.file_paths = file_paths; self.labels = labels\n",
    "        self.target_width = target_width; self.augment = augment\n",
    "    def __len__(self): return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]; label = self.labels[idx]\n",
    "        audio, sr = librosa.load(file_path, res_type='kaiser_fast', duration=3, sr=22050*2, offset=0.5)\n",
    "        if self.augment: audio = augmenter(samples=audio, sample_rate=sr)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
    "        db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        current_width = db_spectrogram.shape[1]\n",
    "        if current_width < self.target_width: db_spectrogram = np.pad(db_spectrogram, ((0, 0), (0, self.target_width - current_width)), mode='constant')\n",
    "        elif current_width > self.target_width: db_spectrogram = db_spectrogram[:, :self.target_width]\n",
    "        spec_min, spec_max = db_spectrogram.min(), db_spectrogram.max()\n",
    "        if spec_max > spec_min: db_spectrogram = (db_spectrogram - spec_min) / (spec_max - spec_min)\n",
    "        spectrogram_3ch = np.stack([db_spectrogram, db_spectrogram, db_spectrogram], axis=0)\n",
    "        return torch.tensor(spectrogram_3ch, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# --- Prepare Data ---\n",
    "all_files = []; all_labels = []\n",
    "for root, dirs, files in os.walk(AUDIO_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'): all_files.append(os.path.join(root, file))\n",
    "all_labels = [emotion_map[os.path.basename(f).split(\"-\")[2]] for f in all_files]\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels)\n",
    "train_dataset = AudioDataset(train_files, train_labels, augment=True)\n",
    "val_dataset = AudioDataset(val_files, val_labels, augment=False)\n",
    "test_dataset = AudioDataset(test_files, test_labels, augment=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True); val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False); test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Initialize Model and Optimizer ---\n",
    "model = models.resnet18(weights='IMAGENET1K_V1'); model.fc = nn.Linear(model.fc.in_features, len(emotion_labels_list)); model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE); criterion = nn.CrossEntropyLoss(); scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# --- Training Loop with Early Stopping ---\n",
    "best_val_acc = 0.0\n",
    "print(\"Starting main training with augmentation and early stopping...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train(); running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(); outputs = model(inputs); loss = criterion(outputs, labels)\n",
    "        loss.backward(); optimizer.step(); running_loss += loss.item() * inputs.size(0)\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "\n",
    "    model.eval(); val_loss = 0.0; correct = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs); loss = criterion(outputs, labels); val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1); total += labels.size(0); correct += (predicted == labels).sum().item()\n",
    "    val_accuracy = 100 * correct / total; val_loss /= len(val_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        print(f\"ğŸ‰ New best validation accuracy: {best_val_acc:.2f}%. Saving model...\")\n",
    "        torch.save({'epoch': epoch + 1, 'model_state_dict': model.state_dict()}, CHECKPOINT_BEST_PATH)\n",
    "    scheduler.step()\n",
    "\n",
    "# --- Final Evaluation on Test Set ---\n",
    "print(\"\\n--- FINAL EVALUATION ON RAVDESS TEST SET ---\")\n",
    "print(f\"Loading best model from epoch with accuracy: {best_val_acc:.2f}%\")\n",
    "best_checkpoint = torch.load(CHECKPOINT_BEST_PATH); model.load_state_dict(best_checkpoint['model_state_dict']); model.eval()\n",
    "all_preds = []; all_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs); _, preds = torch.max(outputs, 1); all_preds.extend(preds.cpu().numpy()); all_true.extend(labels.cpu().numpy())\n",
    "accuracy = accuracy_score(all_true, all_preds)\n",
    "print(f\"Final Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\"); print(classification_report(all_true, all_preds, target_names=emotion_labels_list, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The Moment of Truth - Quantifying the Domain Gap\n",
    "\n",
    "This is the most critical experiment so far. We take our best Specialist model, which was trained *only* on the clean, acted speech of the RAVDESS dataset, and evaluate its performance on the unseen CREMA-D dataset, which contains more natural, crowd-sourced speech.\n",
    "\n",
    "This test will give us a hard number that quantifies the \"Domain Gap\"â€”the performance drop when a model is faced with data different from what it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 826209,
     "status": "ok",
     "timestamp": 1756710854236,
     "user": {
      "displayName": "Monsur Abdullah",
      "userId": "12726162145146472590"
     },
     "user_tz": -360
    },
    "id": "NbNQIk4Vtmd5",
    "outputId": "e261e69c-5843-45ae-b0d1-7af5cc256720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting audio to spectrogram conversion for CREMA-D...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CREMA-D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7442/7442 [11:33<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREMA-D spectrogram conversion complete.\n",
      "\n",
      "Loading best model for cross-corpus evaluation...\n",
      "\n",
      "--- EVALUATION ON CREMA-D DATASET ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating on CREMA-D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233/233 [01:44<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy on CREMA-D: 22.39%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.26      0.03      0.05      1087\n",
      "       happy       0.30      0.02      0.04      1271\n",
      "         sad       0.23      0.64      0.34      1271\n",
      "       angry       0.84      0.08      0.15      1271\n",
      "     fearful       0.24      0.36      0.28      1271\n",
      "     disgust       0.42      0.19      0.26      1271\n",
      "\n",
      "   micro avg       0.26      0.22      0.24      7442\n",
      "   macro avg       0.38      0.22      0.19      7442\n",
      "weighted avg       0.38      0.22      0.19      7442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- This cell tests the best model on the CREMA-D dataset ---\n",
    "# Make sure you have uploaded and unzipped CREMA-D to this path\n",
    "CREMA_D_AUDIO_PATH = \"/content/drive/MyDrive/ser_project/crema_d_data/AudioWAV/\"\n",
    "CREMA_D_SPECTROGRAM_PATH = \"/content/drive/MyDrive/ser_project/crema_d_spectrograms/\"\n",
    "CHECKPOINT_BEST_PATH = \"/content/drive/MyDrive/ser_project/resnet_best_augmented.pth\"\n",
    "\n",
    "# === PART A: PREPROCESS CREMA-D ===\n",
    "os.makedirs(CREMA_D_SPECTROGRAM_PATH, exist_ok=True)\n",
    "print(\"\\nStarting audio to spectrogram conversion for CREMA-D...\")\n",
    "crema_d_files_to_process = [f for f in os.listdir(CREMA_D_AUDIO_PATH) if f.endswith('.wav')]\n",
    "for file_name in tqdm(crema_d_files_to_process, desc=\"Processing CREMA-D\"):\n",
    "    try:\n",
    "        file_path = os.path.join(CREMA_D_AUDIO_PATH, file_name)\n",
    "        audio, sr = librosa.load(file_path, res_type='kaiser_fast', duration=3, sr=22050*2, offset=0.5)\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128, fmax=8000)\n",
    "        db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        output_filename = os.path.join(CREMA_D_SPECTROGRAM_PATH, f\"{os.path.splitext(file_name)[0]}.npy\")\n",
    "        np.save(output_filename, db_spectrogram)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing {file_path}: {e}\")\n",
    "print(\"\\nCREMA-D spectrogram conversion complete.\")\n",
    "\n",
    "# === PART B: EVALUATE ON CREMA-D ===\n",
    "# --- Mappings and Dataset ---\n",
    "crema_d_emotion_map = { \"NEU\": 0, \"HAP\": 2, \"SAD\": 3, \"ANG\": 4, \"FEA\": 5, \"DIS\": 6 }\n",
    "# Note: We are mapping to the original 8-class indices that the model was trained on\n",
    "class CremaDDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_width=300):\n",
    "        self.file_paths, self.labels, self.target_width = file_paths, labels, target_width\n",
    "    def __len__(self): return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = np.load(self.file_paths[idx]); label = self.labels[idx]\n",
    "        current_width = spectrogram.shape[1]\n",
    "        if current_width < self.target_width: spectrogram = np.pad(spectrogram, ((0, 0), (0, self.target_width - current_width)), mode='constant')\n",
    "        elif current_width > self.target_width: spectrogram = spectrogram[:, :self.target_width]\n",
    "        spec_min, spec_max = spectrogram.min(), spectrogram.max()\n",
    "        if spec_max > spec_min: spectrogram = (spectrogram - spec_min) / (spec_max - spec_min)\n",
    "        spectrogram_3ch = np.stack([spectrogram, spectrogram, spectrogram], axis=0)\n",
    "        return torch.tensor(spectrogram_3ch, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "crema_d_files = [os.path.join(CREMA_D_SPECTROGRAM_PATH, f) for f in os.listdir(CREMA_D_SPECTROGRAM_PATH) if f.endswith('.npy')]\n",
    "crema_d_labels = [crema_d_emotion_map[os.path.basename(f).split(\"_\")[2]] for f in crema_d_files]\n",
    "test_dataset = CremaDDataset(crema_d_files, crema_d_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Load Model and Evaluate ---\n",
    "print(\"\\nLoading best model for cross-corpus evaluation...\")\n",
    "model = models.resnet18(); model.fc = nn.Linear(model.fc.in_features, 8);\n",
    "best_checkpoint = torch.load(CHECKPOINT_BEST_PATH); model.load_state_dict(best_checkpoint['model_state_dict']); model = model.to(device); model.eval()\n",
    "print(\"\\n--- EVALUATION ON CREMA-D DATASET ---\")\n",
    "all_preds, all_true = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating on CREMA-D\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs); _, preds = torch.max(outputs, 1); all_preds.extend(preds.cpu().numpy()); all_true.extend(labels.cpu().numpy())\n",
    "accuracy = accuracy_score(all_true, all_preds)\n",
    "print(f\"Final Model Accuracy on CREMA-D: {accuracy * 100:.2f}%\")\n",
    "report_labels_indices = sorted(list(set(crema_d_labels))); report_labels_names = [emotion_labels_list[i] for i in report_labels_indices]\n",
    "print(\"\\nClassification Report:\"); print(classification_report(all_true, all_preds, labels=report_labels_indices, target_names=report_labels_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: A Failed First Attempt - Exploring Knowledge Distillation\n",
    "\n",
    "With the domain gap clearly measured, we explore a potential solution. Knowledge Distillation is a technique where a smaller \"student\" model (our simple AudioCNN) is trained to mimic the predictions of a larger \"teacher\" model (our robust ResNet18). The hypothesis is that the student might learn a more compact and generalizable representation of the teacher's knowledge.\n",
    "\n",
    "As the results show, this experiment was a valuable failure, demonstrating that distilling knowledge from a non-generalizing teacher is not a viable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332527,
     "status": "ok",
     "timestamp": 1756714544530,
     "user": {
      "displayName": "Monsur Abdullah",
      "userId": "12726162145146472590"
     },
     "user_tz": -360
    },
    "id": "pg2Yw8lrtrav",
    "outputId": "2986e32f-a8f5-45d2-b26d-a42a8596f4eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Teacher model (ResNet18)...\n",
      "Initializing Student model (AudioCNN)...\n",
      "Starting distillation training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:32<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Distillation Loss: 11.8160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Distillation Loss: 7.8196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Distillation Loss: 7.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Distillation Loss: 7.7833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Distillation Loss: 7.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Distillation Loss: 7.7612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Distillation Loss: 7.7532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Distillation Loss: 7.7477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Distillation Loss: 7.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Distillation Loss: 7.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Distillation Loss: 7.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Distillation Loss: 7.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Distillation Loss: 7.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Distillation Loss: 7.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Distillation Loss: 7.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Distillation Loss: 7.7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Distillation Loss: 7.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Distillation Loss: 7.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Distillation Loss: 7.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Distillation Loss: 7.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Distillation Loss: 7.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Distillation Loss: 7.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Distillation Loss: 7.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Distillation Loss: 7.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Distillation Loss: 7.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Distillation Loss: 7.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Distillation Loss: 7.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Distillation Loss: 7.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Distillation Loss: 7.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Distillation Loss: 7.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Distillation Loss: 7.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Distillation Loss: 7.7287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Distillation Loss: 7.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Distillation Loss: 7.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Distillation Loss: 7.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Distillation Loss: 7.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Distillation Loss: 7.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Distillation Loss: 7.7287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Distillation Loss: 7.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Distillation Loss: 7.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Distillation Loss: 7.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Distillation Loss: 7.7294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:06<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Distillation Loss: 7.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Distillation Loss: 7.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:05<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Distillation Loss: 7.7288\n",
      "\n",
      "--- FINAL EVALUATION OF DISTILLED STUDENT MODEL ---\n",
      "Student Model Accuracy: 13.19%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.00      0.00      0.00        19\n",
      "        calm       0.00      0.00      0.00        38\n",
      "       happy       0.00      0.00      0.00        38\n",
      "         sad       0.13      1.00      0.23        38\n",
      "       angry       0.00      0.00      0.00        39\n",
      "     fearful       0.00      0.00      0.00        39\n",
      "     disgust       0.00      0.00      0.00        38\n",
      "    surprise       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.13       288\n",
      "   macro avg       0.02      0.12      0.03       288\n",
      "weighted avg       0.02      0.13      0.03       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- This script trains a small 'student' CNN using the large 'teacher' ResNet18 ---\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "\n",
    "# --- Configuration ---\n",
    "SPECTROGRAM_PATH = \"/content/drive/MyDrive/ser_project/ravdess_spectrograms/\"\n",
    "TEACHER_CHECKPOINT_PATH = \"/content/drive/MyDrive/ser_project/resnet_best_augmented.pth\"\n",
    "STUDENT_CHECKPOINT_PATH = \"/content/drive/MyDrive/ser_project/student_cnn_distilled.pth\"\n",
    "LEARNING_RATE = 0.005; BATCH_SIZE = 32; EPOCHS = 50\n",
    "TEMPERATURE = 4.0; ALPHA = 0.3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Mappings and Dataset (using pre-computed spectrograms for speed) ---\n",
    "emotion_map = { \"01\": 0, \"02\": 1, \"03\": 2, \"04\": 3, \"05\": 4, \"06\": 5, \"07\": 6, \"08\": 7 }\n",
    "emotion_labels_list = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprise\"]\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, target_width=300):\n",
    "        self.file_paths, self.labels, self.target_width = file_paths, labels, target_width\n",
    "    def __len__(self): return len(self.file_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = np.load(self.file_paths[idx]); label = self.labels[idx]\n",
    "        current_width = spectrogram.shape[1]\n",
    "        if current_width < self.target_width: spectrogram = np.pad(spectrogram, ((0, 0), (0, self.target_width - current_width)), mode='constant')\n",
    "        elif current_width > self.target_width: spectrogram = spectrogram[:, :self.target_width]\n",
    "        spec_min, spec_max = spectrogram.min(), spectrogram.max()\n",
    "        if spec_max > spec_min: spectrogram = (spectrogram - spec_min) / (spec_max - spec_min)\n",
    "        spectrogram_3ch = np.stack([spectrogram, spectrogram, spectrogram], axis=0)\n",
    "        return torch.tensor(spectrogram_3ch, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# --- Student Model Definition (AudioCNN Modified for 3-Channel Input) ---\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8, flattened_size=9216):\n",
    "        super(AudioCNN, self).__init__(); self.conv1 = nn.Conv2d(3, 16, 3, 1, 1); self.bn1 = nn.BatchNorm2d(16); self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1); self.bn2 = nn.BatchNorm2d(32); self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1); self.bn3 = nn.BatchNorm2d(64); self.pool3 = nn.MaxPool2d(4, 4)\n",
    "        self.flatten = nn.Flatten(); self.fc1 = nn.Linear(flattened_size, 128); self.dropout = nn.Dropout(0.5); self.fc2 = nn.Linear(128, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x)))); x = self.pool2(F.relu(self.bn2(self.conv2(x)))); x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x); x = F.relu(self.fc1(x)); x = self.dropout(x); x = self.fc2(x); return x\n",
    "\n",
    "# --- Prepare Data ---\n",
    "all_files = [os.path.join(SPECTROGRAM_PATH, f) for f in os.listdir(SPECTROGRAM_PATH) if f.endswith('.npy')]\n",
    "all_labels = [emotion_map[os.path.basename(f).split(\"-\")[2]] for f in all_files]\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_files, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
    "train_dataset = SpectrogramDataset(train_files, train_labels); test_dataset = SpectrogramDataset(test_files, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True); test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- Load Teacher Model ---\n",
    "print(\"Loading Teacher model (ResNet18)...\")\n",
    "teacher_model = models.resnet18(); teacher_model.fc = nn.Linear(teacher_model.fc.in_features, len(emotion_labels_list))\n",
    "teacher_checkpoint = torch.load(TEACHER_CHECKPOINT_PATH); teacher_model.load_state_dict(teacher_checkpoint['model_state_dict'])\n",
    "teacher_model = teacher_model.to(device); teacher_model.eval()\n",
    "\n",
    "# --- Initialize Student Model ---\n",
    "print(\"Initializing Student model (AudioCNN)...\")\n",
    "student_model = AudioCNN(num_classes=8, flattened_size=9216).to(device)\n",
    "\n",
    "# --- Optimizer and Loss Functions ---\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=LEARNING_RATE)\n",
    "criterion_ce = nn.CrossEntropyLoss(); criterion_kd = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# --- Distillation Training Loop ---\n",
    "print(\"Starting distillation training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    student_model.train(); running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad(): teacher_outputs = teacher_model(inputs)\n",
    "        student_outputs = student_model(inputs)\n",
    "        loss_ce = criterion_ce(student_outputs, labels)\n",
    "        soft_teacher = F.softmax(teacher_outputs / TEMPERATURE, dim=1)\n",
    "        soft_student = F.log_softmax(student_outputs / TEMPERATURE, dim=1)\n",
    "        loss_kd = criterion_kd(soft_student, soft_teacher)\n",
    "        loss = ALPHA * loss_ce + (1.0 - ALPHA) * (TEMPERATURE**2) * loss_kd\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset); print(f\"Epoch {epoch+1}/{EPOCHS} - Distillation Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# --- Final Evaluation of Student Model ---\n",
    "student_model.eval(); all_preds, all_true = [], []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = student_model(inputs); _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy()); all_true.extend(labels.cpu().numpy())\n",
    "accuracy = accuracy_score(all_true, all_preds)\n",
    "print(f\"\\n--- FINAL EVALUATION OF DISTILLED STUDENT MODEL ---\")\n",
    "print(f\"Student Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\"); print(classification_report(all_true, all_preds, target_names=emotion_labels_list, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNOuOkudV6LlSPM3dUdmZek",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
